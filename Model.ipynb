{"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8039073,"sourceType":"datasetVersion","datasetId":4739489}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndata_chunks = pd.read_csv('/kaggle/input/tender-hack/data.csv', chunksize=10000, sep=';')\ncharacteristics_chunks = pd.read_csv('/kaggle/input/tender-hack/characteristic.csv', chunksize=10000, sep=';')\n\nmerged_data = pd.DataFrame()\nfor data_chunk, characteristics_chunk in zip(data_chunks, characteristics_chunks):\n    data_chunk = data_chunk.rename(columns = {\"ID\" : \"id\",\n                                              \"Название СТЕ\" : \"STE\",\n                                              \"Ссылка на изображение\" : \"url_image\",\n                                              \"ID конечной категории Портала\" : \"id_final_category_portal\",\n                                              \"Модель\" : \"model\",\n                                              \"Производитель\" : \"producer\"})\n    characteristics_chunk = characteristics_chunk.rename(columns={\"ID характеристики\" : \"id_characteristic\",\n                                                                  \"Название характеристики\" : \"name_characteristic\",\n                                                                  \"ID конечной категории Портала\" : \"id_final_category_portal\",\n                                                                  \"Наименование конечной категории Портала\" : \"name_final_category_portal\",\n                                                                  \"Тип значения характеристики\" : \"type_value_characteristic\"})\n    merged_chunk = pd.merge(data_chunk, characteristics_chunk, on='id_final_category_portal')\n    merged_data = pd.concat([merged_data, merged_chunk], ignore_index=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":712},"id":"E4OipIdUpX_z","outputId":"7626fcac-a883-4114-86ec-e0a3dbe34ee4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выбор нужных столбцов\nselected_columns = ['STE', 'id', 'name_final_category_portal', 'id_final_category_portal']\nresult_data = merged_data[selected_columns]\n\n# Удаление дубликатов\nresult_data = result_data.drop_duplicates()\nresult_data.head()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"PX_pdQw6rn5w","outputId":"faa13eac-ca69-4172-810e-32b58b2da7fc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_category(df, id_category):\n    category = df.query(\"id_final_category_portal == @id_category\").name_final_category_portal.head(1).values[0]\n    return category\nget_category(result_data, 793373188)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport pymorphy2\n\nmorph = pymorphy2.MorphAnalyzer()\ndef pp(text):\n    text = text.lower()\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\w*\\d\\w*', '', text)\n    text = re.sub(r'\\b\\w{1}\\b', '', text)\n    text = re.sub(r'\\b[a-z]+\\b', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    words = text.split()\n    filtered_words = [word for word in words if morph.word_is_known(word)]\n    return ' '.join(filtered_words)\n    return text","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tp7bs4b72dvH","outputId":"c5d3312a-494c-4397-8b42-d905b4f90bf8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pymorphy2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U transformers\n!pip install -q -U accelerate\n!pip install -q -U bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(torch.__version__)\nprint(torch.cuda.is_available())\nprint(torch.version.cuda)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame({'category_id': result_data['id_final_category_portal'],\n                     'ste_name': result_data['STE'].apply(pp)})\ndata.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Dropout, Conv1D, LSTM, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Преобразование category_id для обучения\ncategory_mapping = {id: idx for idx, id in enumerate(sorted(data['category_id'].unique()))}\ndata['category_id'] = data['category_id'].map(category_mapping)\n\n# Разбиение на обучающую и тестовую выборки\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Токенизация и векторизация текста\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_data['ste_name'])\ntrain_sequences = tokenizer.texts_to_sequences(train_data['ste_name'])\ntest_sequences = tokenizer.texts_to_sequences(test_data['ste_name'])\n\nmax_length = 50\ntrain_padded = pad_sequences(train_sequences, maxlen=max_length)\ntest_padded = pad_sequences(test_sequences, maxlen=max_length)\n\n# Создание модели с использованием Bidirectional LSTM и Conv1D\nmodel = Sequential([\n    Embedding(len(tokenizer.word_index) + 1, 100),\n    Conv1D(64, 5, activation='relu'),\n    Bidirectional(LSTM(64, return_sequences=True)),\n    GlobalAveragePooling1D(),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(len(category_mapping), activation='softmax')\n])\n\nmodel.compile(optimizer=Adam(learning_rate=0.001),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Использование EarlyStopping для предотвращения переобучения\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Обучение модели\nmodel.fit(train_padded, train_data['category_id'],\n          batch_size=128, epochs=50,\n          validation_data=(test_padded, test_data['category_id']),\n          callbacks=[early_stopping])\n\n# Функция для предсказания топ-5 категорий\ndef predict_top5_categories(ste_name):\n    sequence = tokenizer.texts_to_sequences([ste_name])\n    padded = pad_sequences(sequence, maxlen=max_length)\n    probs = model.predict(padded)[0]\n    top5_ids = probs.argsort()[-5:][::-1]\n    top5_category_ids = [list(category_mapping.keys())[list(category_mapping.values()).index(i)] for i in top5_ids]\n    return top5_category_ids\n\n# Пример использования\nste_name = 'ноутбук черный'\ntop5_category_ids = predict_top5_categories(ste_name)\nprint(f\"Top-5 категорий для товара '{ste_name}': {top5_category_ids}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}